{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "metadata": {
        "id": "mEIOC06i7QEJ"
      },
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "\n",
        "uri = \"https://gist.githubusercontent.com/guilhermesilveira/2d2efa37d66b6c84a722ea627a897ced/raw/10968b997d885cbded1c92938c7a9912ba41c615/tracking.csv\"\n",
        "dados = pd.read_csv(uri)\n",
        "dados.head()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "id": "uDu0eTJn7x0D"
      },
      "cell_type": "code",
      "source": [
        "mapa = {\n",
        "    \"home\" : \"principal\",\n",
        "    \"how_it_works\" : \"como_funciona\",\n",
        "    \"contact\" : \"contato\",\n",
        "    \"bought\" : \"comprou\"\n",
        "}\n",
        "dados = dados.rename(columns = mapa)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "id": "9En1V0PM7e8V"
      },
      "cell_type": "code",
      "source": [
        "x = dados[[\"principal\",\"como_funciona\",\"contato\"]]\n",
        "x.head()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "id": "qDr2YoWu8O3O"
      },
      "cell_type": "code",
      "source": [
        "y = dados[\"comprou\"]\n",
        "y.head()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "id": "X5pZ6xcZ8fYq"
      },
      "cell_type": "code",
      "source": [
        "dados.shape"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Separando treino e teste manualmente"
      ],
      "metadata": {
        "id": "Ul_Sm_nRAFbK"
      }
    },
    {
      "metadata": {
        "id": "TLZ9eTvP9U9q"
      },
      "cell_type": "code",
      "source": [
        "treino_x = x[:75]\n",
        "treino_y = y[:75]\n",
        "teste_x = x[75:]\n",
        "teste_y = y[75:]\n",
        "\n",
        "print(\"Treinaremos com %d elementos e testaremos com %d elementos\" % (len(treino_x), len(teste_x)))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "id": "pZZjbQxh9jn8"
      },
      "cell_type": "code",
      "source": [
        "from sklearn.svm import LinearSVC\n",
        "from sklearn.metrics import accuracy_score\n",
        "\n",
        "modelo = LinearSVC()\n",
        "modelo.fit(treino_x, treino_y)\n",
        "previsoes = modelo.predict(teste_x)\n",
        "\n",
        "acuracia = accuracy_score(teste_y, previsoes) * 100\n",
        "print(\"A acurácia foi %.2f%%\" % acuracia)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "id": "2iVcuGkyA5tK"
      },
      "cell_type": "markdown",
      "source": [
        "# Usando a biblioteca para separar treino e teste"
      ]
    },
    {
      "metadata": {
        "id": "rA-z0_a6-CM1"
      },
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.svm import LinearSVC\n",
        "from sklearn.metrics import accuracy_score\n",
        "\n",
        "# o algorítimo train_test_split, por padrão, realiza aleatoriamente a\n",
        "# separação de dados de treino e teste.\n",
        "# Para que o projeto seja replicável, usamos o comando abaixo\n",
        "# que serve para definir a ordem dos números aleatórios\n",
        "SEED = 20\n",
        "\n",
        "treino_x, teste_x, treino_y, teste_y = train_test_split(x, y, random_state = SEED, test_size = 0.25)\n",
        "print(f\"Treinaremos com {len(treino_x)} elementos e testaremos com {len(teste_x)} elementos\")\n",
        "\n",
        "modelo = LinearSVC()\n",
        "modelo.fit(treino_x, treino_y)\n",
        "previsoes = modelo.predict(teste_x)\n",
        "\n",
        "acuracia = accuracy_score(teste_y, previsoes) * 100\n",
        "print(f\"A acurácia foi {acuracia:.2f}%\")\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "id": "JWFKlQccAk1F"
      },
      "cell_type": "code",
      "source": [
        "# saber quantas pessoas compraram e quantas não compraram\n",
        "treino_y.value_counts()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "id": "fdORezxWBcwX"
      },
      "cell_type": "code",
      "source": [
        "teste_y.value_counts()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Se dividirmos 47 por 27 teremos 1,74. Portanto, para cada pessoa que comprou o produto, temos duas que não compraram. Já no teste temos 19 dividido por 6, que totaliza 3,1 - três pessoas que não compraram para cada uma que comprou.\n",
        "\n",
        "Isso significa que a separação entre os dados de treino e teste não está proporcional de acordo com as nossas categorias, o que é bastante arriscado. Por exemplo, se treinarmos apenas com pessoas que não compraram o produto, o algoritimo só saberá que pessoas não compram e esse será o seu palpite padrão pois ele nunca aprendeu que usuários de fato compram o produto.\n",
        "\n",
        "Portanto, é importante que a proporção dos nossos dados seja similar. Para isso, inseriremos mais um argumento na separação de dados (**train_test_split**): o **stratify = y**, que irá estratificar os dados proporcionalmente de acordo com y."
      ],
      "metadata": {
        "id": "3gjXY_MvCMRW"
      }
    },
    {
      "metadata": {
        "id": "k_kFDoBABh4B"
      },
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.svm import LinearSVC\n",
        "from sklearn.metrics import accuracy_score\n",
        "\n",
        "SEED = 20\n",
        "\n",
        "treino_x, teste_x, treino_y, teste_y = train_test_split(x, y,\n",
        "                                                         random_state = SEED, test_size = 0.25,\n",
        "                                                         stratify = y)\n",
        "print(f\"Treinaremos com {len(treino_x)} elementos e testaremos com {len(teste_x)} elementos\")\n",
        "\n",
        "modelo = LinearSVC()\n",
        "modelo.fit(treino_x, treino_y)\n",
        "previsoes = modelo.predict(teste_x)\n",
        "\n",
        "acuracia = accuracy_score(teste_y, previsoes) * 100\n",
        "print(f\"A acurácia foi {acuracia:.2f}%\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "id": "SS4n0CVXB6Fo"
      },
      "cell_type": "code",
      "source": [
        "treino_y.value_counts()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "id": "hgvSvos6CHIk"
      },
      "cell_type": "code",
      "source": [
        "teste_y.value_counts()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Essa é uma técnica que utilizamos para manter a proporção na divisão dos dados. Contudo, se uma das classes aparecesse de forma muito pontual, não seria interessante esse recurso."
      ],
      "metadata": {
        "id": "FM6VBaiODL3P"
      }
    }
  ]
}