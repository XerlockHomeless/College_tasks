{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Xfb9u_BLHSKB"
      },
      "source": [
        "<img alt=\"Colaboratory logo\" width=\"15%\" src=\"https://raw.githubusercontent.com/carlosfab/escola-data-science/master/img/novo_logo_bg_claro.png\">\n",
        "\n",
        "#### **Data Science na Prática 3.0**\n",
        "*by [sigmoidal.ai](https://sigmoidal.ai)*\n",
        "\n",
        "---"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KFLHPTosySU6"
      },
      "source": [
        "# Dados de treino e teste\n",
        "\n",
        "Parte vital de qualquer projeto de Ciência de Dados é fazer o split dos dados da forma e no momento certo.\n",
        "\n",
        "<center><img src=\"https://machinecurve.com/static/images/feed-3.jpg\" width=400px ></center>\n",
        "\n",
        "\n",
        "Isso acontece para que não haja vazamento de dados, que pode causar *overfitting*, o que significa, em termos simples, que o nosso modelo não aprendeu a resolver o problema, e sim, decorou as respostas.\n",
        "\n",
        "<center><img src=\"https://miro.medium.com/max/1396/1*lARssDbZVTvk4S-Dk1g-eA.png\" width=400px ></center>\n",
        "\n",
        "*Overfitting* é um grande problema em qualquer tipo de trabalho com Machine Learning, como podemos ver na imagem. Um bom modelo não precisa ser perfeito, com uma acurácia de 100%. Inclusive, uma acurácia de 100% seria um fortíssimo indicativo de *overfitting*, sendo motivo de preoucupação em um projeto, e não de celebração.\n",
        "\n",
        "Bons modelos são generalistas o suficiente para entender as nuances do poroblema e se adaptarem a novos dados de forma efetiva. Isso é o que buscamos.\n",
        "\n",
        "Mas como alcançar isso?\n",
        "\n",
        "É claro que precisamos nos atentar a diversos detalhes e passos no processo de Machine Learning, mas, por enquanto, vamos nos ater ao *split*, ou divisão do conjunto de dados.\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "684-VcQH22as"
      },
      "source": [
        "## **Separando o Dataset**\n",
        "\n",
        "Ao recebermos um conjunto de dados completo, o primeiro passo é serpará-lo, como demonstra a primeira figura. Entãom, dividiremos o conjunto inteiro entre `Treino` e `Teste`, e então separaremos o de `Treino` entre `Treino` e `Validação`.\n",
        "\n",
        "<center><img src=\"https://miro.medium.com/max/1400/1*RJS8yV5mBDqrRu7THooH-w.png\" width=400px ></center>\n",
        "\n",
        "### **Treino**\n",
        "\n",
        "O conjunto de treino será o maior, e será usado para a análise de dados, para criação do pipeline de processamento desses dados, e também para criar nossa *baseline*, que usaremos para selecionar o modelo a ser otimizado.\n",
        "\n",
        "### **Validação**\n",
        "\n",
        "Esse pedaço do conjunto de treino, será mais ou menos do mesmo tamanho do conjunto de teste, e será usado como um conjunto de teste. Isso significa que o modelo criado não pode ter visto esses dados na análise, assim como os de teste. Por isso esses conjuntos são comumente chamados de *\"holdout sets\"*, pois vamos \"segurá-los\" até o momento certo de usá-los.\n",
        "\n",
        "No caso do conjunto de validação, nós vamos ter construído e selecionado o modelo, ou modelos, a serem otimizados. Nessa parte, usaremos o conjunto para fazer o tuning de parâmetros, e selecionar o melhor modelo, que será usado em produção, entregue ao cliente, etc.\n",
        "\n",
        "### **Teste**\n",
        "\n",
        "Esse conjunto é utilizado apenas no final, com o seu modelo pronto, e otimizado, para testar o resultado do modelo pronto com dados novos, da mesma forma que ele receberá esses dados no mundo real. Aqui é onde saberemos a verdadeira performance do modelo, e avaliaremos a mesma baseado nas métricas de interesse para o problema.\n",
        "\n",
        "Parece confuso, mas na prática, é mais simples.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5JHE6ctHw_Fh"
      },
      "outputs": [],
      "source": [
        "# importar os pacotes necessários\n",
        "import pandas as pd\n",
        "\n",
        "# importar o arquivo\n",
        "df = pd.read_csv(r\"./csvs/precificacao_housing_plus.csv\")\n",
        "\n",
        "# ver as primeiras entradas\n",
        "print(df.shape)\n",
        "df.head()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "l67go34sIgTp"
      },
      "source": [
        "Ao carregar seu conjunto de dados, separe uma fração dele para ser seu conjunto de teste. É normal ver a proporção 70/15/15 para os conjuntos, mas não é uma regra.\n",
        "\n",
        "Ainda mais hoje em dia com Big Data, não é absurdo uma proporção 95/2.5/2.5, dado o grande volume de dados, e a importância de ser ter um grande conjunto de treino.\n",
        "\n",
        "No exemplo abaixo, vou usar 15% do dataset como conjunto de teste."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "VOJT5FlH6qGo"
      },
      "outputs": [],
      "source": [
        "# criando o conjunto de teste\n",
        "test = df.sample(frac=0.15, random_state=0)\n",
        "\n",
        "# verificando o conjunto\n",
        "print(test.shape)\n",
        "test.head()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OHh0PeWrI8uC"
      },
      "source": [
        "Uma vez selecionado nosso teste, precisamos retirar as entradas selecionadas do dataset original, para evitar duplicidade de entradas e vazamento de dados."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vi7e84Rw69hW"
      },
      "outputs": [],
      "source": [
        "# drop das linhas de teste\n",
        "df = df.drop(test.index)\n",
        "\n",
        "# verificando o shape do df\n",
        "df.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Kxncr66cISdh"
      },
      "outputs": [],
      "source": [
        "# resetando o index dos conjuntos\n",
        "df.reset_index()\n",
        "test.reset_index()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5fGFrVtYKW3w"
      },
      "source": [
        "Com nosso conjunto de testes reservado, podemos fazer o split no conjunto de treino para o conjunto de validação com o Scikit-Learn."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "utdOKeadxShc"
      },
      "outputs": [],
      "source": [
        "# importando o módulo necessário\n",
        "from sklearn.model_selection import train_test_split"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "tuw_N_yd1uNm"
      },
      "outputs": [],
      "source": [
        "# drop do Target\n",
        "X = df.drop('SalePrice', axis=1)\n",
        "y = df['SalePrice']"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zGa5siPSK5tP"
      },
      "outputs": [],
      "source": [
        "# fazendo o split\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.15)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "AckLj0QBLLVx"
      },
      "outputs": [],
      "source": [
        "print(X_train.shape)\n",
        "print(X_test.shape)\n",
        "print(y_train.shape)\n",
        "print(y_test.shape)\n",
        "print(df.shape)"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "venv",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.6"
    },
    "vscode": {
      "interpreter": {
        "hash": "e6cd63dbf4f8b52cfec474863eba38f847d5d4c1020d9e353c9f84619ddcdf73"
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
